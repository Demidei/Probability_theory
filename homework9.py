import math
import scipy.stats
import statistics
import numpy as np
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt


# Задача 1: Даны значения величины заработной платы заемщиков банка (zp) и значения их поведенческого кредитного скоринга (ks): zp = [35, 45, 190, 200, 40, 70, 54, 150, 120, 110], ks = [401, 574, 874, 919, 459, 739, 653, 902, 746, 832]. Используя математические операции, посчитать коэффициенты линейной регрессии, приняв за X заработную плату (то есть, zp - признак), а за y - значения скорингового балла (то есть, ks - целевая переменная). Произвести расчет как с использованием intercept, так и без.

# Полагаю можно попробовать сделать аналогично лекции

zp = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110])
ks = np.array([401, 574, 874, 919, 459, 739, 653, 902, 746, 832])

# zp = np.array([27, 37, 42, 48, 57, 56, 77, 80])
# ks = np.array([1.2, 1.6, 1.8, 2.5, 2.6, 3, 3.3])

b1 = (len(zp)*np.sum(ks*zp)-np.sum(zp)*np.sum(ks)) / \
    (len(zp)*np.sum(zp**2)-np.sum(zp**2))

b0 = np.mean(ks)-b1*np.mean(zp)

print("Задача 1 коэффициент -", b1)
print("Задача 1 константа -", b0)

y = b0+b1*zp

mse1 = ((ks-y)**2).sum()/len(zp)
print("Задача 1 функция потерь без встроенных функций -", mse1)

# Теперь попробуем встроенные функции

model = LinearRegression()
zp = zp.reshape(-1, 1)


model.fit(zp, ks)

print("Задача 1 коэффициент для встроенных функций -", model.coef_[0])
print("Задача 1 константа для встроенных функций -", model.intercept_)


zp = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110])
z = zp * model.coef_[0] + model.intercept_

mse2 = ((ks-z)**2).sum()/len(zp)
print("Задача 1 функция потерь для встроенных функций -", mse2)

# У меня складывается впечатление, что встроенные функции дают приближение лучше

# Задача 2: Посчитать коэффициент линейной регрессии при заработной плате (zp), используя градиентный спуск (без intercept).

# Сделаем как на лекции и посмотрим что получится! Переопределю массивы для большей осторожности

zp = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110])
ks = np.array([401, 574, 874, 919, 459, 739, 653, 902, 746, 832])

a = 1e-6

b1 = 0.1

for i in range(10000):
    b1 -= a*(2/len(zp))*np.sum((b1*zp-ks)*zp)

y = b1*zp
mse = ((ks-y)**2).sum()/len(zp)


print("Задача 2 коэффициент -", b1)

print("Задача 2 функция потерь -", mse)


# Складывается впечатление, что точность не очень высока.
# Я подумал, что можно было бы сделать случайную генерацию стартового значения коэффициента и величины шага, но ручной перебор значений показал, что значение mse не становится меньше 56516 в любом случае. Наверное это бессмысленно

# Задача 3: (Дополнительно). Произвести вычисления как в пункте 2, но с вычислением intercept. Учесть, что изменение коэффициентов должно производиться на каждом шаге одновременно (то есть изменение одного коэффициента не должно влиять на изменение другого во время одной итерации).

# Не то чтобы я был особенно хорош в производных, но есть те кто что-то такое решал до меня

zp = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110])
ks = np.array([401, 574, 874, 919, 459, 739, 653, 902, 746, 832])

a = 1e-6

b1 = 0.1
b0 = 0.1

for i in range(100000):
    b1_temp =b1- a*(-2)*np.sum((ks-b1*zp-b0)*zp)
    b0_temp=b0- a*(-2)*np.sum((ks-b1*zp-b0))
    b1=b1_temp
    b0=b0_temp

y = b1*zp+b0
mse = ((ks-y)**2).sum()/len(zp)


print("Задача 3 коэффициент -", b1)

print("Задача 3 константа -", b0)


print("Задача 3 функция потерь -", mse)

